{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Pre_processingDS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGia4HhRJI9N"
      },
      "source": [
        "Deep learning project code , Arabic dilects identification "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6SOqwb-GuZ3",
        "outputId": "039f36ed-025d-4749-c582-1265f6a5ac09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfv8efJipbUJ",
        "outputId": "f3d81209-996b-46bf-b530-9bf4e58d8432",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "'''\n",
        "load data\n",
        "'''\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import multiprocessing\n",
        "import io\n",
        "import seaborn as sns\n",
        "from sklearn import datasets\n",
        "from sklearn import preprocessing #to normalize data\n",
        "import re\n",
        "import csv\n",
        "print(\"hello world!\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "import nltk # for processing texts\n",
        "from nltk.corpus import stopwords # list of stop words\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello world!\n",
            "Mounted at /gdrive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/gdrive/My Drive/Project-DataSceince/train.csv', sep='\\t',encoding = 'utf-16')\n",
        "valid = pd.read_csv('/gdrive/My Drive/Project-DataSceince/valid.csv', sep='\\t',encoding = 'utf-16')\n",
        "test = pd.read_csv('/gdrive/My Drive/Project-DataSceince/test.csv', sep='\\t',encoding = 'utf-16')"
      ],
      "metadata": {
        "id": "PY2VUBFs4ZPC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk3O62c4RkVJ"
      },
      "source": [
        "Text Normalization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Explore the train data\n",
        "train.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "M1HRimqIqnDe",
        "outputId": "8324ef0f-084d-45bd-f8f8-682749de1c76"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text     label\n",
              "0  بالإضافة لقيام معلمو الجيزة للذهاب إلي جريدة ا...       MSA\n",
              "1  بعدين والله حرام تجي تلقى الي واقف عند الاشاره...       MSA\n",
              "2                   لمسه اليد مرتين واضحة جدا والحكم  DIAL_LEV\n",
              "3                   بخصوص الهاتريك عمرها ما راح تصير  DIAL_LEV\n",
              "4      الله يجبر كسرهم ويرجع و لدهم اليوم قبل بكرى ،  DIAL_GLF"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5116a66c-a492-41de-8ae9-c81b7df66569\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>بالإضافة لقيام معلمو الجيزة للذهاب إلي جريدة ا...</td>\n",
              "      <td>MSA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>بعدين والله حرام تجي تلقى الي واقف عند الاشاره...</td>\n",
              "      <td>MSA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>لمسه اليد مرتين واضحة جدا والحكم</td>\n",
              "      <td>DIAL_LEV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>بخصوص الهاتريك عمرها ما راح تصير</td>\n",
              "      <td>DIAL_LEV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>الله يجبر كسرهم ويرجع و لدهم اليوم قبل بكرى ،</td>\n",
              "      <td>DIAL_GLF</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5116a66c-a492-41de-8ae9-c81b7df66569')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5116a66c-a492-41de-8ae9-c81b7df66569 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5116a66c-a492-41de-8ae9-c81b7df66569');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Explore the valid data\n",
        "valid.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "R3XMK-wurVvM",
        "outputId": "a25767d9-07f5-416e-da9b-302710048356"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           text     label\n",
              "0       تصور كل ده كله . . تلاقيني باحبك أكتر .  DIAL_EGY\n",
              "1                          أكتر من روحي باحبك .  DIAL_EGY\n",
              "2  وتصور حب المخلص لحبيبه اللي ولا بأيه يتغير .  DIAL_EGY\n",
              "3       تصور كل ده كله . . تلاقيني باحبك أكتر .  DIAL_EGY\n",
              "4    أكتر من روحي باحبك . . بحقيقي باحبك أكتر .  DIAL_EGY"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7329b267-a1d6-4009-967c-5317faa422be\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>تصور كل ده كله . . تلاقيني باحبك أكتر .</td>\n",
              "      <td>DIAL_EGY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>أكتر من روحي باحبك .</td>\n",
              "      <td>DIAL_EGY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>وتصور حب المخلص لحبيبه اللي ولا بأيه يتغير .</td>\n",
              "      <td>DIAL_EGY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>تصور كل ده كله . . تلاقيني باحبك أكتر .</td>\n",
              "      <td>DIAL_EGY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>أكتر من روحي باحبك . . بحقيقي باحبك أكتر .</td>\n",
              "      <td>DIAL_EGY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7329b267-a1d6-4009-967c-5317faa422be')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7329b267-a1d6-4009-967c-5317faa422be button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7329b267-a1d6-4009-967c-5317faa422be');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSrFecsp_6p_"
      },
      "source": [
        "import sys\n",
        "import re\n",
        "#sys.setdefaultencoding('utf-8')\n",
        "##########################Clean Text Data #######################################\n",
        "########################Global Variable Declaration##############################\n",
        "\n",
        "#################################################################################\n",
        "\n",
        "def normalize(sent):\n",
        "    \"\"\"clean data from any English char, emoticons, underscore, and repeated > 2\n",
        "    str -> str\"\"\"\n",
        "    p1 = re.compile('\\W')\n",
        "    p2 = re.compile('\\s+')\n",
        "    sent = ReplaceThreeOrMore(sent)\n",
        "    sent = sent.replace('_', ' ')\n",
        "    sent = re.sub(r'[A-Za-z0-9]', r'', sent)\n",
        "    sent = re.sub(p1, ' ', sent)\n",
        "    sent = re.sub(p2, ' ', sent)\n",
        "    return sent\n",
        "def ReplaceThreeOrMore(s):\n",
        "    # pattern to look for three or more repetitions of any character, including\n",
        "    # newlines.\n",
        "    pattern = re.compile(r\"(.)\\1{2,}\", re.DOTALL)\n",
        "    return pattern.sub(r\"\\1\\1\", s)\n",
        "def norm_alif(text):\n",
        "    text = text.replace(u\"\\u0625\", u\"\\u0627\")  # HAMZA below, with LETTER ALEF\n",
        "    #text = text.replace(u\"\\u0621\", u\"\\u0627\")  # HAMZA, with LETTER ALEF\n",
        "    text = text.replace(u\"\\u0622\", u\"\\u0627\")  # ALEF WITH MADDA ABOVE, with LETTER ALEF\n",
        "    #text = text.replace(u\"\\u0623\", u\"\\u0627\")  # ALEF WITH HAMZA ABOVE, with LETTER ALEF\n",
        "    return text\n",
        "def remove_unicode_diac(text):\n",
        "    \"\"\"Takes Arabic in utf-8 and returns same text without diac\"\"\"\n",
        "    # Replace diacritics with nothing\n",
        "    text = text.replace(u\"\\u064B\", \"\")  # fatHatayn\n",
        "    text = text.replace(u\"\\u064C\", \"\")  # Dammatayn\n",
        "    text = text.replace(u\"\\u064D\", \"\")  # kasratayn\n",
        "    text = text.replace(u\"\\u064E\", \"\")  # fatHa\n",
        "    text = text.replace(u\"\\u064F\", \"\")  # Damma\n",
        "    text = text.replace(u\"\\u0650\", \"\")  # kasra\n",
        "    text = text.replace(u\"\\u0651\", \"\")  # shaddah\n",
        "    text = text.replace(u\"\\u0652\", \"\")  # sukuun\n",
        "    text = text.replace(u\"\\u0670\", \"`\")  # dagger 'alif\n",
        "    return text\n",
        "# def norm_taa(text):\n",
        "#     text=text.replace(u\"\\u0629\", u\"\\u0647\") # taa' marbuuTa, with haa'\n",
        "#     #text=text.replace(u\"\\u064A\", u\"\\u0649\") # yaa' with 'alif maqSuura\n",
        "#     return text\n",
        "# def norm_yaa(text):\n",
        "#     if len(text)!=0:\n",
        "#         if text[-1] == u\"\\u064A\":\n",
        "#             text = text.replace(u\"\\u064A\", u\"\\u0649\")  # yaa' with 'alif maqSuura\n",
        "#     return text\n",
        "\n",
        "def NormForWord2Vec(text):\n",
        "    # text=norm_taa(text)\n",
        "    # text=norm_yaa(text)\n",
        "    text=norm_alif(text)\n",
        "    return text\n",
        "\n",
        "def remove_nonunicode2(Tweet):\n",
        "    ## defining set of unicode ##\n",
        "    #u\"\"\n",
        "    #Tweet=Tweet.decode(\"utf-8\")\n",
        "    UniLex={ ## This is list of all arabic unicode characters in addition to space (to separate words)\n",
        "            u\"\\u0622\",\n",
        "            u\"\\u0626\",\n",
        "            u\"\\u0628\",\n",
        "            u\"\\u062a\",\n",
        "            u\"\\u062c\",\n",
        "            u\"\\u06af\",\n",
        "            u\"\\u062e\",\n",
        "            u\"\\u0630\",\n",
        "            u\"\\u0632\",\n",
        "            u\"\\u0634\",\n",
        "            u\"\\u0636\",\n",
        "            u\"\\u0638\",\n",
        "            u\"\\u063a\",\n",
        "            u\"\\u0640\",\n",
        "            u\"\\u0642\",\n",
        "            u\"\\u0644\",\n",
        "            u\"\\u0646\",\n",
        "            u\"\\u0648\",\n",
        "            u\"\\u064a\",\n",
        "            u\"\\u0670\",\n",
        "            u\"\\u067e\",\n",
        "            u\"\\u0686\",\n",
        "            u\"\\u0621\",\n",
        "            u\"\\u0623\",\n",
        "            u\"\\u0625\",\n",
        "            u\"\\u06a4\",\n",
        "            u\"\\u0627\",\n",
        "            u\"\\u0629\",\n",
        "            u\"\\u062b\",\n",
        "            u\"\\u062d\",\n",
        "            u\"\\u062f\",\n",
        "            u\"\\u0631\",\n",
        "            u\"\\u0633\",\n",
        "            u\"\\u0635\",\n",
        "            u\"\\u0637\",\n",
        "            u\"\\u0639\",\n",
        "            u\"\\u0641\",\n",
        "            u\"\\u0643\",\n",
        "            u\"\\u0645\",\n",
        "            u\"\\u0647\",\n",
        "            u\"\\u0649\",\n",
        "            u\"\\u0671\",\n",
        "            ' ',\n",
        "            '\\n'\n",
        "          }\n",
        "    fin_tweet=\"\"\n",
        "    for c in Tweet:\n",
        "        if c in UniLex:\n",
        "           fin_tweet=fin_tweet+c\n",
        "    return fin_tweet\n",
        "\n",
        "###### Heuristics Calculations ######\n",
        "def diac_counter(text):\n",
        "    #text=text.decode(\"utf-8\")\n",
        "    diac = [u\"\\u064B\",u\"\\u064C\", u\"\\u064D\", u\"\\u064E\", u\"\\u064F\", u\"\\u0650\", u\"\\u0651\", u\"\\u0652\", u\"\\u0670\"]\n",
        "    diac_count=0\n",
        "    for d in diac:\n",
        "        diac_count+=text.count(d)\n",
        "#         if d in text:\n",
        "#             print(d)\n",
        "#             diac_count+=1\n",
        "    return diac_count\n",
        "def check_seed(list_seeds, text):\n",
        "    \"\"\n",
        "    for word in list_seeds:\n",
        "        text = text.lower()\n",
        "        if word.decode(\"utf-8\") in text:\n",
        "            return True\n",
        "    return False\n",
        "def EnglishCount(text):\n",
        "    printable = ['e', 'a', 'o', 't', 'i']\n",
        "    count = 0\n",
        "    for ch in printable:\n",
        "        count += text.count(ch.lower())\n",
        "    return count\n",
        "########################################\n",
        "\n",
        "\n",
        "\n",
        "def eliminate_single_char_words(Tweet):\n",
        "    parts = Tweet.split(\" \")\n",
        "    cleaned_line_parts = []\n",
        "    for P in parts:\n",
        "        if len(P) != 1:\n",
        "            cleaned_line_parts.append(P)\n",
        "    cleaned_line = ' '.join(cleaned_line_parts)\n",
        "    return cleaned_line\n",
        "def clean_unicode(Tweet):\n",
        "    tweet=normalize(Tweet.strip(\"\\n\"))\n",
        "    if len(tweet) !=0:\n",
        "        sentence = []\n",
        "        for word in tweet.split(\" \"):\n",
        "            word = remove_unicode_diac(word)\n",
        "            word = norm_alif(word)\n",
        "            # word = norm_taa(word)\n",
        "            # word = norm_yaa(word)\n",
        "            word = normalize(word)\n",
        "            word = Remove_stopword(word)\n",
        "            sentence.append(word)\n",
        "        tweet = ' '.join(sentence)\n",
        "        tweet =remove_nonunicode2(tweet)\n",
        "        tweet =eliminate_single_char_words(tweet)\n",
        "    return tweet\n",
        "\n",
        "def NormCorpusFinal(Tweet):\n",
        "    tweet=KeepUniOnly(Tweet)\n",
        "    tweet=NormForWord2Vec(tweet)\n",
        "    return tweet\n",
        "\n",
        "def KeepUniOnly(Tweet):## this one is without normalization\n",
        "    tweet=Tweet.replace(\"# \",\" \")\n",
        "    tweet=tweet.replace(\"#\",\" \")\n",
        "    tweet=tweet.replace(\"_\",\" \")\n",
        "    tweet=tweet.replace(u\"\\u0657\",\" \")\n",
        "    tweet=tweet.replace(\"\\n\",\" \")\n",
        "    tweet=tweet.replace(\"[\",\" \")\n",
        "    tweet=tweet.replace(\"]\",\" \")\n",
        "    tweet=tweet.replace(\"?\",\" \")\n",
        "    tweet=tweet.replace(\"!\",\" \")\n",
        "    tweet=remove_nonunicode2(tweet)\n",
        "    tweet=eliminate_single_char_words(tweet)\n",
        "    tweet=ReplaceThreeOrMore(tweet)\n",
        "    return tweet\n",
        "\n",
        "def get_charset(rawtext):\n",
        "    chars = sorted(list(set(rawtext)))\n",
        "    return chars\n",
        "\n",
        "def DialectChecker(text):\n",
        "    ##Based on Hueristics done by Hassan\n",
        "    if (diac_counter(text)>5 or check_seed(list_seeds,text) or EnglishCount(text)>4 or \"<URL>\"  in text\n",
        "        or text.count('#') >2 or '\"'  in text or text.count('@') or \"\\\"RT\" in text or len(text.split(\" \")) <7):\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "def Remove_stopword(text):\n",
        "\n",
        "  text = ' '.join([word for word in text.split() if word not in stopwords.words(\"arabic\")]) # remove stop word\n",
        "  #text = re.sub(' +', ' ',text) # remove extra space\n",
        "  #text = text.strip() #remove whitespaces\n",
        "  return text\n",
        "\n",
        "###############################################################"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laivGgAD5IjI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1025f87-d478-431d-ac2e-011973803c00"
      },
      "source": [
        "train.iloc[20000][0], train.iloc[20000][1]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('كل يوم نسمع صفقات انتقال اللاعبين من والى وبصفقات خيالية تصل الى مئات ملايين الدولارات وتنقل الصحافة الاخبار الى الرياضيين . . . لكن هل يوجد للاعبيناسوق انتقال منظمة ومحمية بالقانون الاردني وغير مخفية على الصحافةوخاصة مع تطبق نظام الاحتراف . . . ام ان الاتدية لازالت تمارس الضغط المعنوي والنفسي والمادي على اللاعبين حتى لايعرف الواحد راسة من رجلية . . . ويمارس حريتةالرياضية داخل النادي',\n",
              " 'MSA')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WpFhFFxAPnk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c511913d-433c-4794-fec5-f0c514f74102"
      },
      "source": [
        "norm_alif(\"اصيل ابو حق أ ئ ء~\")\n",
        "remove_nonunicode2(\"تاىبسشهيبللاشخسعيهىحشءةخئ بهلارسيعخؤشسىنحةمو الايتىنة  يهتؤخشنس GUHBDICNKMAX\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'تاىبسشهيبللاشخسعيهىحشءةخئ بهلارسيعخشسىنحةمو الايتىنة  يهتخشنس '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBwMAU3QEJKm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02054b37-6f13-4988-a9a9-cc0ad183e399"
      },
      "source": [
        "for row in range(0, 10):\n",
        "  print (normalize(valid.iloc[row][0]) )"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "تصور كل ده كله تلاقيني باحبك أكتر \n",
            "أكتر من روحي باحبك \n",
            "وتصور حب المخلص لحبيبه اللي ولا بأيه يتغير \n",
            "أكتر من روحي باحبك بحقيقي باحبك أكتر \n",
            "وغنايا بكلمة أحبك بالنسبة لدرجة حبك رمز صغير مش أكتر \n",
            "وتصور حب الأزهار لربيعها يجي يزوق ويعطر \n",
            "حب الأطيار ف عششها لصغارها لحد ما تكبر \n",
            "حب الكروان للمغنى بالليل لوليف مستنظر \n",
            "حب الحران للنسمة ف الصيف والجو محرر \n",
            "أكتر من روحي باحبك اهداء الى كل محبى وعشاق نادى الزمالك احلى ناس فى الدنيا انشر ياناشر يا احلى\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save**\n"
      ],
      "metadata": {
        "id": "y82GalGyK6_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"train=\", train.shape)\n",
        "print(\"valid=\", valid.shape)"
      ],
      "metadata": {
        "id": "nny_7iZ2LePT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e42e65f-48f5-464f-ca5d-c34408b11850"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train= (79594, 2)\n",
            "valid= (9727, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.fillna(\"nan\")\n",
        "train.dropna(inplace=True)\n",
        "print('Missing values in train data :',train.isnull().sum().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56It1kbLntQB",
        "outputId": "bdf8cc7e-59fc-4785-a22e-9360ee33533b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in train data : 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for row in range(0, 500):\n",
        "  print(clean_unicode(train.iloc[row][0]) )"
      ],
      "metadata": {
        "id": "ntlhxQdUn7Fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid.fillna(\"nan\")\n",
        "valid.dropna(inplace=True)\n",
        "print('Missing values in valid data :',valid.isnull().sum().sum())"
      ],
      "metadata": {
        "id": "YJecNl-fdW5R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d163d362-ea0a-40b8-e7e2-507ab69dc234"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in valid data : 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.fillna(\"nan\")\n",
        "test.dropna(inplace=True)\n",
        "print('Missing values in test data :',test.isnull().sum().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcc3CeSby5Ns",
        "outputId": "05073e76-e132-48d4-aab8-1374338edeb4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in test data : 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.drop_duplicates(inplace = True)\n",
        "valid.drop_duplicates(inplace = True)\n",
        "test.drop_duplicates(inplace = True)\n",
        "\n"
      ],
      "metadata": {
        "id": "C9RByzZV4XqV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"train=\", train.shape)\n",
        "# print(\"test=\", test.shape)"
      ],
      "metadata": {
        "id": "5huQKR17L7op",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "015be338-0d94-4857-9bb6-a4e5d2ced801"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train= (79590, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize train data , output = x,y\n",
        "\n",
        "with open('/gdrive/My Drive/Project-DataSceince/Normalized_train.csv', 'w') as file:\n",
        "    clean_country = csv.writer(file)\n",
        "    clean_country.writerow(['tweet_content', 'label'])\n",
        "    for row in  range(0, 79590):\n",
        "     clean_country.writerow([clean_unicode(train.iloc[row][0]),train.iloc[row][1]])"
      ],
      "metadata": {
        "id": "9LbK4Rdex_30"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"valid=\", valid.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9n5kGTeEysw5",
        "outputId": "9dfa65f5-9171-4360-d336-edba66fa767f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valid= (9727, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize valid data , output = x,y\n",
        "\n",
        "with open('/gdrive/My Drive/Project-DataSceince/Normalized_valid.csv', 'w') as file:\n",
        "    clean_country = csv.writer(file)\n",
        "    clean_country.writerow(['tweet_content', 'label'])\n",
        "    for row in  range(0, 9727):\n",
        "     clean_country.writerow([clean_unicode(valid.iloc[row][0]),valid.iloc[row][1]])"
      ],
      "metadata": {
        "id": "_B_sWXPWygaw"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"test=\", test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10EZnAl_yyIJ",
        "outputId": "3ca856a3-8fc1-48a2-8175-586899ed6110"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test= (10209, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize valid data , output = x,y\n",
        "\n",
        "with open('/gdrive/My Drive/Project-DataSceince/Normalized_test.csv', 'w') as file:\n",
        "    clean_country = csv.writer(file)\n",
        "    clean_country.writerow(['tweet_content', 'label'])\n",
        "    for row in  range(0, 10209):\n",
        "     clean_country.writerow([clean_unicode(test.iloc[row][0]),test.iloc[row][1]])"
      ],
      "metadata": {
        "id": "ewQcKMeYTuXW"
      },
      "execution_count": 33,
      "outputs": []
    }
  ]
}